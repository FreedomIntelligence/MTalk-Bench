<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="MTalk-Bench: Evaluating Speech-to-Speech Models in Multi-Turn Dialogues">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>MTalk-Bench: Evaluating Speech-to-Speech Models in Multi-Turn Dialogues via Arena-style and Rubrics Protocols</title>
  
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.4/css/bulma.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.4/css/academicons.min.css">

  <style>
    body {
      font-family: 'Noto Sans', sans-serif;
    }

    .publication-title {
      font-family: 'Google Sans', sans-serif;
    }

    .publication-authors {
      font-family: 'Google Sans', sans-serif;
    }

    .publication-authors a {
      color: hsl(204, 86%, 53%) !important;
    }

    .publication-authors a:hover {
      text-decoration: underline;
    }

    .author-block {
      display: inline-block;
    }

    .eql-cntrb { 
      font-size: smaller;
    }

    /* Custom Carousel Styles */
    .carousel-container {
      position: relative;
      overflow: hidden;
      width: 100%;
      height: 500px; /* å‡å°‘é«˜åº¦ */
    }

    .carousel-wrapper {
      display: flex;
      transition: transform 0.5s ease-in-out;
      height: 100%;
    }

    .carousel-item {
      min-width: 100%;
      flex-shrink: 0;
      display: flex;
      align-items: center;
      justify-content: center;
      padding: 1rem; /* å‡å°‘å†…è¾¹è· */
    }

    .carousel-item figure {
      width: 100%;
      max-width: 900px; /* å¢åŠ æœ€å¤§å®½åº¦ */
      margin: 0 auto;
    }

    .carousel-item img {
      width: 100%;
      height: auto;
      border-radius: 12px;
      box-shadow: 0 8px 32px rgba(0,0,0,0.1);
    }

    /* Navigation buttons */
    .carousel-nav {
      position: absolute;
      top: 50%;
      transform: translateY(-50%);
      background: rgba(0,0,0,0.7);
      color: white;
      border: none;
      width: 50px;
      height: 50px;
      border-radius: 50%;
      cursor: pointer;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 18px;
      z-index: 10;
      transition: background-color 0.3s ease;
    }

    .carousel-nav:hover {
      background: rgba(0,0,0,0.9);
    }

    .carousel-nav-left {
      left: 20px;
    }

    .carousel-nav-right {
      right: 20px;
    }

    /* Pagination dots */
    .carousel-pagination {
      display: flex;
      justify-content: center;
      gap: 10px;
      margin-top: 1rem;
    }

    .carousel-dot {
      width: 12px;
      height: 12px;
      border-radius: 50%;
      background: #ccc;
      cursor: pointer;
      transition: background-color 0.3s ease;
    }

    .carousel-dot.active {
      background: #3273dc;
    }

    /* Demo cards styling */
    .demo-card {
      background: white;
      border-radius: 16px;
      padding: 2rem;
      box-shadow: 0 4px 20px rgba(0,0,0,0.1);
      height: 100%;
    }

    .demo-audio {
      width: 100%;
      margin-bottom: 0.5rem;
    }

    .set-block {
      border-left: 3px solid #3273dc;
      padding-left: 1rem;
      margin: 1rem 0;
    }

    .demo-card .subcap {
      border-radius: 9999px;
      padding: 0.25rem 0.6rem;
      font-weight: 600;
      border: none;
    }
    
    /* åˆ†åœºæ™¯é…è‰²ï¼šå„è‡ªå”¯ä¸€é¢œè‰² */
    .demo-card[data-demo="Semantic"] .subcap {
      background-color: #2b8a3e; /* ç»¿è‰² */
      color: #fff;
    }
    .demo-card[data-demo="Paralinguistic"] .subcap {
      background-color: #6f42c1; /* ç´«è‰² */
      color: #fff;
    }
    .demo-card[data-demo="Ambient"] .subcap {
      background-color: #1e88e5; /* è“è‰² */
      color: #fff;
    }
    .key-findings li {
      margin-bottom: 1rem;
      padding: 0.5rem 0;
    }

    /* Results carousel specific styling - è°ƒæ•´å¸ƒå±€ä½¿captionåœ¨å›¾ç‰‡ä¸‹æ–¹ */
    .results-carousel-container {
      height: 600px; /* å‡å°‘é«˜åº¦ */
    }

    .results-carousel-item .card {
      height: 100%;
      display: flex;
      flex-direction: column;
    }

    .results-carousel-item .card-content {
      flex: 1;
      display: flex;
      flex-direction: column;
      padding: 0.5rem; /* å‡å°‘å†…è¾¹è· */
    }

    .results-carousel-item figure {
      flex: 1;
      display: flex;
      flex-direction: column; /* æ”¹ä¸ºçºµå‘å¸ƒå±€ */
      justify-content: center;
      align-items: center;
      margin: 0; /* ç§»é™¤é»˜è®¤è¾¹è· */
    }

    .results-carousel-item figure img {
      width: 100%;
      height: auto;
      max-height: 450px; /* å‡å°‘å›¾ç‰‡æœ€å¤§é«˜åº¦ */
      object-fit: contain;
    }

    .figure-caption,
    .image-caption {
      margin-top: 0.75rem; /* å‡å°‘ä¸Šè¾¹è· */
      margin-bottom: 0; /* ç§»é™¤ä¸‹è¾¹è· */
      font-size: 0.95rem;
      line-height: 1.4;
      color: rgba(0,0,0,0.7);
      text-align: center;
      width: 100%;
    }

    /* å‡å°‘sectionä¹‹é—´çš„é—´è· */
    .section {
      padding: 2rem 1.5rem; /* å‡å°‘sectionçš„padding */
    }

    .hero.is-small .hero-body {
      padding: 1.5rem 1.5rem; /* å‡å°‘heroçš„padding */
    }

    /* Compact spacing for the two findings sections */
    #results-analysis .content,
    #meta-eval .content {
      line-height: 1.5;              /* æ”¶ç´§æ®µå†…è¡Œè· */
    }
    
    #results-analysis .key-findings,
    #meta-eval .key-findings {
      margin-top: 0.25rem;           /* æ”¶ç´§åˆ—è¡¨ä¸Šä¸‹ç©ºç™½ */
      margin-bottom: 0.75rem;
    }
    
    #results-analysis .key-findings li,
    #meta-eval .key-findings li {
      margin-bottom: 0.35rem;        /* æ”¶ç´§æ¡ç›®é—´è·ï¼ˆåŸæ¥æ˜¯ 1remï¼‰ */
      padding: 0.15rem 0;            /* æ”¶ç´§æ¡ç›®å†…è¾¹è·ï¼ˆåŸæ¥æ˜¯ 0.5rem 0ï¼‰ */
      line-height: 1.45;             /* å­å¼¹æ¡ç›®æ–‡æœ¬è¡Œè·æ›´ç´§ä¸€ç‚¹ */
    }
  </style>
</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">MTalk-Bench: Evaluating Speech-to-Speech Models in Multi-Turn Dialogues via Arena-style and Rubrics Protocols</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="#" target="_blank">First Author</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="#" target="_blank">Second Author</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="#" target="_blank">Third Author</a>
                  </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">Institution Name<br>Conference name and year</span>
              <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="#" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="fas fa-file-pdf"></i></span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://huggingface.co/datasets/FreedomIntelligence/MTalk-Bench" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span>ğŸ¤— Dataset</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://github.com/FreedomIntelligence/MTalk-Bench" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="fab fa-github"></i></span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              The rapid advancement of speech-to-speech (S2S) large language models (LLMs) has significantly improved real-time spoken interaction.  However, current evaluation frameworks remain inadequate for assessing performance in complex, multi-turn dialogues. 
              To address this, we introduce <strong>MTalk-Bench</strong>, a multi-turn S2S benchmark covering three core dimensions: 
              <em>Semantic Information</em>, <em>Paralinguistic Information</em>, and <em>Ambient Sound</em>. 
              Each dimension includes nine realistic scenarios, along with targeted tasks to assess specific capabilities such as reasoning. 
              Our dual-method evaluation framework combines <em>Arena-style</em> evaluation (pairwise comparison) and <em>Rubrics-based</em> 
              evaluation (absolute scoring) for relative and absolute assessment. The benchmark includes both model and human outputs, evaluated by 
              human evaluators and LLMs. 
              Experimental results reveal two sets of findings. <strong>Overall performance of S2S LLMs:</strong> 
              (1) models excel at semantic information processing yet underperform on paralinguistic information and ambient sounds perception; 
              (2) Models typically regain coherence by increasing response length, sacrificing efficiency in multi-turn dialogues; 
              (3) modality-aware, task-specific designs outperform brute scaling. 
              <strong>Evaluation framework and reliability:</strong> 
              (1) Arena and Rubrics yield consistent, complementary rankings, but reliable distinctions emerge only when performance gaps are large; 
              (2) LLM-as-a-judge aligns with humans when gaps are clear or criteria explicit, but exhibits position and length biases and is reliable 
              on nonverbal evaluation only with text annotations. 
              These results highlight current limitations in S2S evaluation and the need for more robust, speech-aware assessment frameworks.
            </p>

          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Framework & Evaluation (Condensed, English-only) -->
<section class="section" id="framework-eval">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Framework &amp; Evaluation</h2>

    <!-- Figures: concise academic captions -->
    <section class="hero is-small" id="figures">
      <div class="hero-body">
        <div class="container">
          <div class="carousel-container">
            <div class="carousel-wrapper" id="fig-carousel-wrapper">
              <!-- Slide 1 -->
              <div class="carousel-item">
                <figure class="image">
                  <img src="static/images/main_structure_comics_new.png" alt="Framework overview" loading="lazy">
                  <figcaption class="figure-caption">
                    <strong>Figure 1. MTalk-Bench overview.</strong> Three speech-aware dimensions
                    (Semantic, Paralinguistic, Ambient) organized into a hierarchical capability taxonomy,
                    evaluated via a <em>dual-method</em> design: pairwise Arena (relative, Elo) and rubric-based scoring (absolute),
                    executed by both human raters and LLM-as-a-judge.
                  </figcaption>
                </figure>
              </div>

              <!-- Slide 2 -->
              <div class="carousel-item">
                <figure class="image">
                  <img src="static/images/Data_construction_comics_new.png" alt="Data pipeline" loading="lazy">
                  <figcaption class="figure-caption">
                    <strong>Figure 2. Data construction pipeline.</strong> Scenarioâ†’capability mapping â†’ multi-turn script authoring â†’
                    human speech recording â†’ Seed-VC timbre conversion (for child/elder voices) â†’ ambient-sound integration
                    (e.g., Freesound / FSD50K / Pixabay) â†’ multi-round QA â†’ inputs to Arena &amp; Rubrics evaluations.
                  </figcaption>
                </figure>
              </div>
            </div>

            <!-- Navigation -->
            <button class="carousel-nav carousel-nav-left" id="fig-prev" aria-label="Previous figure">
              <i class="fas fa-chevron-left" aria-hidden="true"></i>
            </button>
            <button class="carousel-nav carousel-nav-right" id="fig-next" aria-label="Next figure">
              <i class="fas fa-chevron-right" aria-hidden="true"></i>
            </button>
          </div>

          <!-- Pagination -->
          <div class="carousel-pagination" id="fig-pagination" aria-label="Figures pagination">
            <span class="carousel-dot active" data-slide="0"></span>
            <span class="carousel-dot" data-slide="1"></span>
          </div>
        </div>
      </div>
    </section>

    <!-- Text: concise and academic (no duplication with figure captions) -->
    <div class="columns is-variable is-6 is-multiline">
      <div class="column is-12">
        <div class="content has-text-justified">
          <h3 class="title is-4">Framework</h3>
          <p>
            MTalk-Bench spans <em>Semantic</em>, <em>Paralinguistic</em>, and <em>Ambient</em> dimensions, with a two-level capability taxonomy
            (core skills â†’ fine-grained skills). Nine real-world scenarios are linked via a scenarioâ†’capability mapping to ensure ecological validity
            while keeping each dialogue diagnostic by design.
          </p>
        </div>
      </div>

      <div class="column is-12">
        <div class="content has-text-justified">
          <h3 class="title is-4">Evaluation</h3>
          <p>
            We use complementary protocols: <strong>Arena</strong> (blind pairwise preferences aggregated as Elo for relative ordering)
            and <strong>Rubrics</strong> (hierarchical, criteria-based scoring for absolute diagnostics). Both human raters and LLM-as-a-judge
            are employed to balance reliability, scalability, and speech-awareness.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


  
<section class="section" id="demos">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Audio Demos</h2>

    <div class="columns is-multiline is-variable is-4">

      <!-- Semantic -->
      <div class="column is-12-tablet is-4-desktop">
        <div class="box demo-card" data-demo="Semantic">
          <h3 class="title is-5">Semantic</h3>

          <!-- Set 1: Comprehension & Memory -->
          <div class="set-block">
            <div class="set-header">
              <p class="set-title">Set 1-1</p>
              <span class="tag subcap">Comprehension & Memory</span>
            </div>
            <div class="audio-grid">
              <audio class="demo-audio" controls preload="none" aria-label="Semantic 1-1 â€” turn 1">
                <source src="static/audio/1-1-turn1_sem.wav" type="audio/wav">
                Your browser does not support the audio element.
              </audio>
              <audio class="demo-audio" controls preload="none" aria-label="Semantic 1-1 â€” turn 2">
                <source src="static/audio/1-1-turn2_sem.wav" type="audio/wav">
              </audio>
            </div>
          </div>

          <!-- Set 2: Reasoning & Execution -->
          <div class="set-block">
            <div class="set-header">
              <p class="set-title">Set 1-2</p>
              <span class="tag subcap">Reasoning & Execution</span>
            </div>
            <div class="audio-grid">
              <audio class="demo-audio" controls preload="none" aria-label="Semantic 1-2 â€” turn 1">
                <source src="static/audio/1-4-turn1_sem.wav" type="audio/wav">
              </audio>
              <audio class="demo-audio" controls preload="none" aria-label="Semantic 1-2 â€” turn 2">
                <source src="static/audio/1-4-turn2_sem.wav" type="audio/wav">
              </audio>
            </div>
          </div>

          <!-- Set 3: Security & Assessment -->
          <div class="set-block">
            <div class="set-header">
              <p class="set-title">Set 1-3</p>
              <span class="tag subcap">Security & Assessment</span>
            </div>
            <div class="audio-grid">
              <audio class="demo-audio" controls preload="none" aria-label="Semantic 1-3 â€” turn 1">
                <source src="static/audio/1-10-turn1_sem.wav" type="audio/wav">
              </audio>
              <audio class="demo-audio" controls preload="none" aria-label="Semantic 1-3 â€” turn 2">
                <source src="static/audio/1-10-turn2_sem.wav" type="audio/wav">
              </audio>
            </div>
          </div>
        </div>
      </div>

      <!-- Paralinguistic -->
      <div class="column is-12-tablet is-4-desktop">
        <div class="box demo-card" data-demo="Paralinguistic">
          <h3 class="title is-5">Paralinguistic</h3>

          <!-- Set 1: Emotion Recognition -->
          <div class="set-block">
            <div class="set-header">
              <p class="set-title">Set 1-1</p>
              <span class="tag subcap">Emotion Recognition</span>
            </div>
            <div class="audio-grid">
              <audio class="demo-audio" controls preload="none" aria-label="Paralinguistic 1-1 â€” turn 1">
                <source src="static/audio/1-1-turn1_para.wav" type="audio/wav">
              </audio>
              <audio class="demo-audio" controls preload="none" aria-label="Paralinguistic 1-1 â€” turn 2">
                <source src="static/audio/1-1-turn2_para.wav" type="audio/wav">
              </audio>
            </div>
          </div>

          <!-- Set 2: Personalized Expressive Modeling -->
          <div class="set-block">
            <div class="set-header">
              <p class="set-title">Set 1-2</p>
              <span class="tag subcap">Personalized Modeling</span>
            </div>
            <div class="audio-grid">
              <audio class="demo-audio" controls preload="none" aria-label="Paralinguistic 1-2 â€” turn 1">
                <source src="static/audio/1-4-turn1_para.wav" type="audio/wav">
              </audio>
              <audio class="demo-audio" controls preload="none" aria-label="Paralinguistic 1-2 â€” turn 2">
                <source src="static/audio/1-4-turn2_para.wav" type="audio/wav">
              </audio>
            </div>
          </div>

          <!-- Set 3: Feature Generation -->
          <div class="set-block">
            <div class="set-header">
              <p class="set-title">Set 1-3</p>
              <span class="tag subcap">Paralinguistic Feature Generation</span>
            </div>
            <div class="audio-grid">
              <audio class="demo-audio" controls preload="none" aria-label="Paralinguistic 1-3 â€” turn 1">
                <source src="static/audio/1-10-turn1_para.wav" type="audio/wav">
              </audio>
              <audio class="demo-audio" controls preload="none" aria-label="Paralinguistic 1-3 â€” turn 2">
                <source src="static/audio/1-10-turn2_para.wav" type="audio/wav">
              </audio>
            </div>
          </div>
        </div>
      </div>

      <!-- Ambient -->
      <div class="column is-12-tablet is-4-desktop">
        <div class="box demo-card" data-demo="Ambient">
          <h3 class="title is-5">Ambient</h3>


          <!-- Set 1: Ambient Sound Understanding -->
          <div class="set-block">
            <div class="set-header">
              <p class="set-title">Set 1-1</p>
              <span class="tag subcap">Ambient Sound Understanding</span>
            </div>
            <div class="audio-grid">
              <audio class="demo-audio" controls preload="none" aria-label="Ambient sample1 â€” turn 1">
                <source src="static/audio/1-1-turn1_amb.wav" type="audio/wav">
              </audio>
              <audio class="demo-audio" controls preload="none" aria-label="Ambient sample1 â€” turn 2">
                <source src="static/audio/1-1-turn2_amb.wav" type="audio/wav">
              </audio>
            </div>
          </div>

          <!-- Set 2: Ambient Understanding -->
          <div class="set-block">
            <div class="set-header">
              <p class="set-title">Set 1-2</p>
              <span class="tag subcap">Ambient Sound Understanding</span>
            </div>
            <div class="audio-grid">
              <audio class="demo-audio" controls preload="none" aria-label="Ambient sample2 â€” turn 1">
                <source src="static/audio/1-4-turn1_amb.wav" type="audio/wav">
              </audio>
              <audio class="demo-audio" controls preload="none" aria-label="Ambient sample2 â€” turn 2">
                <source src="static/audio/1-4-turn2_amb.wav" type="audio/wav">
              </audio>
            </div>
          </div>

          <!-- Set 3: Multi-party Understanding -->
          <div class="set-block">
            <div class="set-header">
              <p class="set-title">Set 1-3</p>
              <span class="tag subcap">Multi-party Understanding</span>
            </div>
            <div class="audio-grid">
              <audio class="demo-audio" controls preload="none" aria-label="Ambient sample3 â€” turn 1">
                <source src="static/audio/1-10-turn1_amb.wav" type="audio/wav">
              </audio>
              <audio class="demo-audio" controls preload="none" aria-label="Ambient sample3 â€” turn 2">
                <source src="static/audio/1-10-turn2_amb.wav" type="audio/wav">
              </audio>
            </div>
          </div>
        </div>
      </div>

    </div><!-- /columns -->
  </div>
</section>
  

<section class="hero is-small" id="pdf-results">
  <div class="hero-body">
    <h2 class="title is-3 has-text-centered">Results Analysis</h2>
    <div class="container">
      <div class="carousel-container results-carousel-container">
        
        <div class="carousel-wrapper" id="results-carousel-wrapper">

          <!-- Slide: Overall results -->
          <div class="carousel-item results-carousel-item">
            <div class="card" style="border-radius:16px;">
              <div class="card-content">
                <figure class="image">
                  <img src="static/images/audio_eval.png" alt="Overall evaluation results">
                  <figcaption class="figure-caption">
                    <strong>Overall results (Table 2).</strong> Arena (Elo, relative) and Rubrics (Ã—100, absolute)
                    present a consistent landscape across overall and per-dimension scores.
                  </figcaption>
                </figure>
              </div>
            </div>
          </div>

          <!-- Slide: Win rates across evaluators -->
          <div class="carousel-item results-carousel-item">
            <div class="card" style="border-radius:16px;">
              <div class="card-content">
                <figure class="image">
                  <img src="static/images/win_rates.png" alt="Win rates across evaluators">
                  <figcaption class="figure-caption">
                    <strong>Win-rate profiles.</strong> Cross-evaluator win rates show strong systems,
                    yet many model pairs remain statistically tied rather than yielding a single dominant system.
                  </figcaption>
                </figure>
              </div>
            </div>
          </div>

          <!-- Slide: Turn-level trends & duration correlation -->
          <div class="carousel-item results-carousel-item">
            <div class="card" style="border-radius:16px;">
              <div class="card-content">
                <figure class="image">
                  <img src="static/images/turn_level_trends.png" alt="Turn-level trends and duration correlation">
                  <figcaption class="figure-caption">
                    <strong>Turn-level trends &amp; duration correlation.</strong> Quality often dips in early turns and then recovers
                    as responses become longer; duration correlates with higher scores, but gains plateau beyond a minimal length.
                  </figcaption>
                </figure>
              </div>
            </div>
          </div>

          <!-- Slide: Bias analysis -->
          <div class="carousel-item results-carousel-item">
            <div class="card" style="border-radius:16px;">
              <div class="card-content">
                <figure class="image">
                  <img src="static/images/bias_analysis.png" alt="Bias analysis of evaluators">
                  <figcaption class="figure-caption">
                    <strong>LLM-as-judge bias.</strong> Compared to humans (near-neutral positional preference),
                    LLM judges exhibit measurable <em>position</em> and stronger <em>length</em> biases in Arena scoring.
                  </figcaption>
                </figure>
              </div>
            </div>
          </div>

          <!-- Slide: Arenaâ€“Rubrics consistency & pitfalls -->
          <div class="carousel-item results-carousel-item">
            <div class="card" style="border-radius:16px;">
              <div class="card-content">
                <figure class="image">
                  <img src="static/images/arena_rubrics_consistency.png" alt="Consistency and pitfalls">
                  <figcaption class="figure-caption">
                    <strong>Consistency &amp; pitfalls.</strong> The two protocols are broadly consistent with good internal reliability;
                    however, when performance gaps are small, conclusions remain unstable even with more comparisons.
                  </figcaption>
                </figure>
              </div>
            </div>
          </div>

        </div>

        <!-- Navigation -->
        <button class="carousel-nav carousel-nav-left" id="results-prev" aria-label="Previous result">
          <i class="fas fa-chevron-left" aria-hidden="true"></i>
        </button>
        <button class="carousel-nav carousel-nav-right" id="results-next" aria-label="Next result">
          <i class="fas fa-chevron-right" aria-hidden="true"></i>
        </button>
      </div>

      <!-- Pagination -->
      <div class="carousel-pagination" id="results-pagination" aria-label="Results pagination">
        <span class="carousel-dot active" data-slide="0"></span>
        <span class="carousel-dot" data-slide="1"></span>
        <span class="carousel-dot" data-slide="2"></span>
        <span class="carousel-dot" data-slide="3"></span>
        <span class="carousel-dot" data-slide="4"></span>
      </div>
    </div>
  </div>
</section>
  

<!-- Results: Model Performance -->
<section class="section" id="results-analysis">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Experiment Results â€” Model Performance</h2>
    <div class="content has-text-justified">
      <ul class="key-findings">
        <li><strong>Dimension gap:</strong> Models perform best on the <em>Semantic</em> dimension and lag on <em>Paralinguistic</em> and <em>Ambient</em> tasks.</li>
        <li><strong>Dialogue dynamics:</strong> Early-turn quality often dips and later recovers with longer outputs; duration correlates with higher scores but shows diminishing returns.</li>
        <li><strong>Design matters:</strong> Modality-aware, task-specific designs generally outperform brute parameter scaling for multi-turn S2S dialogue.</li>
      </ul>
    </div>
  </div>
</section>

<!-- Meta-Evaluation: Methods & Reliability (English-only) -->
<section class="section" id="meta-eval">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Meta-Evaluation â€” Methods &amp; Reliability</h2>
    <div class="content has-text-justified">
      <ul class="key-findings">
        <li><strong>Arena Ã— Rubrics:</strong> Broadly consistent and complementary â€” relative ordering vs. absolute diagnostics.</li>
        <li><strong>Small margins:</strong> When gaps are small, outcomes remain unstable even with more pairwise comparisons; robust conclusions appear with large gaps.</li>
        <li><strong>LLM-as-judge:</strong> Agreement with humans improves when differences are clear or criteria are explicit, but LLMs show position and length biases; for nonverbal acoustic cues, reliability improves with textual annotations.</li>
        <li><strong>Reliability:</strong> Good internal consistency across protocols; rubric-based assessments show stable correlations under ablations/bootstraps.</li>
      </ul>
    </div>
  </div>
</section>


  

  <!-- BibTeX -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{mtalk-bench-2024,
  title={MTalk-Bench: Evaluating Speech-to-Speech Models in Multi-Turn Dialogues via Arena-style and Rubrics Protocols},
  author={First Author and Second Author and Third Author},
  journal={Conference Name},
  year={2024}
}</code></pre>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <script>
    // Custom Carousel Implementation
    class CustomCarousel {
      constructor(wrapperId, paginationId, prevBtnId, nextBtnId) {
        this.wrapper = document.getElementById(wrapperId);
        this.pagination = document.getElementById(paginationId);
        this.prevBtn = document.getElementById(prevBtnId);
        this.nextBtn = document.getElementById(nextBtnId);
        this.items = this.wrapper.querySelectorAll('.carousel-item');
        this.currentIndex = 0;
        this.autoplayInterval = null;
        
        this.init();
      }
      
      init() {
        this.updateCarousel();
        this.bindEvents();
        this.startAutoplay();
      }
      
      bindEvents() {
        this.prevBtn.addEventListener('click', () => this.prev());
        this.nextBtn.addEventListener('click', () => this.next());
        
        this.pagination.querySelectorAll('.carousel-dot').forEach((dot, index) => {
          dot.addEventListener('click', () => this.goToSlide(index));
        });
        
        // Pause autoplay on hover
        this.wrapper.addEventListener('mouseenter', () => this.stopAutoplay());
        this.wrapper.addEventListener('mouseleave', () => this.startAutoplay());
      }
      
      updateCarousel() {
        const translateX = -this.currentIndex * 100;
        this.wrapper.style.transform = `translateX(${translateX}%)`;
      
        // Update pagination
        this.pagination.querySelectorAll('.carousel-dot').forEach((dot, index) => {
          dot.classList.toggle('active', index === this.currentIndex);
        });
      }
      
      next() {
        this.currentIndex = (this.currentIndex + 1) % this.items.length;
        this.updateCarousel();
      }
      
      prev() {
        this.currentIndex = (this.currentIndex - 1 + this.items.length) % this.items.length;
        this.updateCarousel();
      }
      
      goToSlide(index) {
        this.currentIndex = index;
        this.updateCarousel();
      }
      
      startAutoplay() {
        this.stopAutoplay();
        this.autoplayInterval = setInterval(() => this.next(), 5000);
      }
      
      stopAutoplay() {
        if (this.autoplayInterval) {
          clearInterval(this.autoplayInterval);
          this.autoplayInterval = null;
        }
      }
    }

    // Initialize carousels when DOM is loaded
    document.addEventListener('DOMContentLoaded', () => {
      // Initialize framework figures carousel
      new CustomCarousel(
        'fig-carousel-wrapper',
        'fig-pagination', 
        'fig-prev',
        'fig-next'
      );
      
      // Initialize results carousel (no autoplay)
      const resultsCarousel = new CustomCarousel(
        'results-carousel-wrapper',
        'results-pagination',
        'results-prev', 
        'results-next'
      );
      resultsCarousel.stopAutoplay(); // Disable autoplay for results
    });
  </script>

</body>
</html>

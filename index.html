<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="MTalk-Bench: Evaluating Speech-to-Speech Models in Multi-Turn Dialogues">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>MTalk-Bench: Evaluating Speech-to-Speech Models in Multi-Turn Dialogues via Arena-style and Rubrics Protocols</title>
  
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.4/css/bulma.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.4/css/academicons.min.css">

  <style>
    body {
      font-family: 'Noto Sans', sans-serif;
    }

    .publication-title {
      font-family: 'Google Sans', sans-serif;
    }

    .publication-authors {
      font-family: 'Google Sans', sans-serif;
    }

    .publication-authors a {
      color: hsl(204, 86%, 53%) !important;
    }

    .publication-authors a:hover {
      text-decoration: underline;
    }

    .author-block {
      display: inline-block;
    }

    .eql-cntrb { 
      font-size: smaller;
    }

    /* Custom Carousel Styles */
    .carousel-container {
      position: relative;
      overflow: hidden;
      width: 100%;
      height: 600px; /* Fixed height for consistency */
    }

    .carousel-wrapper {
      display: flex;
      transition: transform 0.5s ease-in-out;
      height: 100%;
    }

    .carousel-item {
      min-width: 100%;
      flex-shrink: 0;
      display: flex;
      align-items: center;
      justify-content: center;
      padding: 2rem;
    }

    .carousel-item figure {
      width: 100%;
      max-width: 800px;
      margin: 0 auto;
    }

    .carousel-item img {
      width: 100%;
      height: auto;
      border-radius: 12px;
      box-shadow: 0 8px 32px rgba(0,0,0,0.1);
    }

    /* Navigation buttons */
    .carousel-nav {
      position: absolute;
      top: 50%;
      transform: translateY(-50%);
      background: rgba(0,0,0,0.7);
      color: white;
      border: none;
      width: 50px;
      height: 50px;
      border-radius: 50%;
      cursor: pointer;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 18px;
      z-index: 10;
      transition: background-color 0.3s ease;
    }

    .carousel-nav:hover {
      background: rgba(0,0,0,0.9);
    }

    .carousel-nav-left {
      left: 20px;
    }

    .carousel-nav-right {
      right: 20px;
    }

    /* Pagination dots */
    .carousel-pagination {
      display: flex;
      justify-content: center;
      gap: 10px;
      margin-top: 1rem;
    }

    .carousel-dot {
      width: 12px;
      height: 12px;
      border-radius: 50%;
      background: #ccc;
      cursor: pointer;
      transition: background-color 0.3s ease;
    }

    .carousel-dot.active {
      background: #3273dc;
    }

    /* Demo cards styling */
    .demo-card {
      background: white;
      border-radius: 16px;
      padding: 2rem;
      box-shadow: 0 4px 20px rgba(0,0,0,0.1);
      height: 100%;
    }

    .demo-audio {
      width: 100%;
      margin-bottom: 0.5rem;
    }

    .set-block {
      border-left: 3px solid #3273dc;
      padding-left: 1rem;
      margin: 1rem 0;
    }

    .demo-card .subcap {
      border-radius: 9999px;
      padding: 0.25rem 0.6rem;
      font-weight: 600;
      border: none;
    }
    
    /* ÂàÜÂú∫ÊôØÈÖçËâ≤ÔºöÂêÑËá™ÂîØ‰∏ÄÈ¢úËâ≤ */
    .demo-card[data-demo="Semantic"] .subcap {
      background-color: #2b8a3e; /* ÁªøËâ≤ */
      color: #fff;
    }
    .demo-card[data-demo="Paralinguistic"] .subcap {
      background-color: #6f42c1; /* Á¥´Ëâ≤ */
      color: #fff;
    }
    .demo-card[data-demo="Ambient"] .subcap {
      background-color: #1e88e5; /* ËìùËâ≤ */
      color: #fff;
    }
    .key-findings li {
      margin-bottom: 1rem;
      padding: 0.5rem 0;
    }

    /* Results carousel specific styling */
    .results-carousel-container {
      height: 700px; /* Larger height for result images */
    }

    .results-carousel-item .card {
      height: 100%;
      display: flex;
      flex-direction: column;
    }

    .results-carousel-item .card-content {
      flex: 1;
      display: flex;
      flex-direction: column;
    }

    .results-carousel-item figure {
      flex: 1;
      display: flex;
      align-items: center;
    }

    .figure-caption,
    .image-caption {
      margin-top: 0.5rem;
      font-size: 0.95rem;
      line-height: 1.4;
      color: rgba(0,0,0,0.7);
      text-align: center;
    }

  </style>
</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">MTalk-Bench: Evaluating Speech-to-Speech Models in Multi-Turn Dialogues via Arena-style and Rubrics Protocols</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="#" target="_blank">First Author</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="#" target="_blank">Second Author</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="#" target="_blank">Third Author</a>
                  </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">Institution Name<br>Conference name and year</span>
              <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="#" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="fas fa-file-pdf"></i></span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://huggingface.co/datasets/FreedomIntelligence/MTalk-Bench" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span>ü§ó Dataset</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://github.com/FreedomIntelligence/MTalk-Bench" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="fab fa-github"></i></span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              The rapid advancement of speech-to-speech (S2S) large language models (LLMs) has significantly improved real-time spoken interaction.  However, current evaluation frameworks remain inadequate for assessing performance in complex, multi-turn dialogues. 
              To address this, we introduce <strong>MTalk-Bench</strong>, a multi-turn S2S benchmark covering three core dimensions: 
              <em>Semantic Information</em>, <em>Paralinguistic Information</em>, and <em>Ambient Sound</em>. 
              Each dimension includes nine realistic scenarios, along with targeted tasks to assess specific capabilities such as reasoning. 
              Our dual-method evaluation framework combines <em>Arena-style</em> evaluation (pairwise comparison) and <em>Rubrics-based</em> 
              evaluation (absolute scoring) for relative and absolute assessment. The benchmark includes both model and human outputs, evaluated by 
              human evaluators and LLMs. 
            </p>
            
            <p>
              Experimental results reveal two sets of findings. <strong>Overall performance of S2S LLMs:</strong> 
              (1) models excel at semantic information processing yet underperform on paralinguistic information and ambient sounds perception; 
              (2) Models typically regain coherence by increasing response length, sacrificing efficiency in multi-turn dialogues; 
              (3) modality-aware, task-specific designs outperform brute scaling. 
            </p>
            
            <p>
              <strong>Evaluation framework and reliability:</strong> 
              (1) Arena and Rubrics yield consistent, complementary rankings, but reliable distinctions emerge only when performance gaps are large; 
              (2) LLM-as-a-judge aligns with humans when gaps are clear or criteria explicit, but exhibits position and length biases and is reliable 
              on nonverbal evaluation only with text annotations. 
            </p>
            
            <p>
              These results highlight current limitations in S2S evaluation and the need for more robust, speech-aware assessment frameworks.
            </p>

          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Framework & Evaluation (Condensed, English-only) -->
<section class="section" id="framework-eval">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Framework &amp; Evaluation</h2>

    <!-- Figures: concise academic captions -->
    <section class="hero is-small" id="figures">
      <div class="hero-body">
        <div class="container">
          <div class="carousel-container">
            <div class="carousel-wrapper" id="fig-carousel-wrapper">
              <!-- Slide 1 -->
              <div class="carousel-item">
                <figure class="image">
                  <img src="static/images/main_structure_comics_new.png" alt="Framework overview" loading="lazy">
                  <figcaption class="figure-caption">
                    <strong>Figure 1. MTalk-Bench overview.</strong> Three speech-aware dimensions
                    (Semantic, Paralinguistic, Ambient) organized into a hierarchical capability taxonomy,
                    evaluated via a <em>dual-method</em> design: pairwise Arena (relative, Elo) and rubric-based scoring (absolute),
                    executed by both human raters and LLM-as-a-judge.
                  </figcaption>
                </figure>
              </div>

              <!-- Slide 2 -->
              <div class="carousel-item">
                <figure class="image">
                  <img src="static/images/Data_construction_comics_new.png" alt="Data pipeline" loading="lazy">
                  <figcaption class="figure-caption">
                    <strong>Figure 2. Data construction pipeline.</strong> Scenario‚Üícapability mapping ‚Üí multi-turn script authoring ‚Üí
                    human speech recording ‚Üí Seed-VC timbre conversion (for child/elder voices) ‚Üí ambient-sound integration
                    (e.g., Freesound / FSD50K / Pixabay) ‚Üí multi-round QA ‚Üí inputs to Arena &amp; Rubrics evaluations.
                  </figcaption>
                </figure>
              </div>
            </div>

            <!-- Navigation -->
            <button class="carousel-nav carousel-nav-left" id="fig-prev" aria-label="Previous figure">
              <i class="fas fa-chevron-left" aria-hidden="true"></i>
            </button>
            <button class="carousel-nav carousel-nav-right" id="fig-next" aria-label="Next figure">
              <i class="fas fa-chevron-right" aria-hidden="true"></i>
            </button>
          </div>

          <!-- Pagination -->
          <div class="carousel-pagination" id="fig-pagination" aria-label="Figures pagination">
            <span class="carousel-dot active" data-slide="0"></span>
            <span class="carousel-dot" data-slide="1"></span>
          </div>
        </div>
      </div>
    </section>

    <!-- Text: concise and academic (no duplication with figure captions) -->
    <div class="columns is-variable is-6 is-multiline">
      <div class="column is-12">
        <div class="content has-text-justified">
          <h3 class="title is-4">Framework</h3>
          <p>
            MTalk-Bench spans <em>Semantic</em>, <em>Paralinguistic</em>, and <em>Ambient</em> dimensions, with a two-level capability taxonomy
            (core skills ‚Üí fine-grained skills). Nine real-world scenarios are linked via a scenario‚Üícapability mapping to ensure ecological validity
            while keeping each dialogue diagnostic by design.
          </p>
        </div>
      </div>

      <div class="column is-12">
        <div class="content has-text-justified">
          <h3 class="title is-4">Evaluation</h3>
          <p>
            We use complementary protocols: <strong>Arena</strong> (blind pairwise preferences aggregated as Elo for relative ordering)
            and <strong>Rubrics</strong> (hierarchical, criteria-based scoring for absolute diagnostics). Both human raters and LLM-as-a-judge
            are employed to balance reliability, scalability, and speech-awareness.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


  
<section class="section" id="demos">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Audio Demos</h2>

    <div class="columns is-multiline is-variable is-4">

      <!-- Semantic -->
      <div class="column is-12-tablet is-4-desktop">
        <div class="box demo-card" data-demo="Semantic">
          <h3 class="title is-5">Semantic</h3>
          <p class="description">
            Tasks across sub-capabilities of semantic understanding.
          </p>

          <!-- Set 1: Comprehension & Memory -->
          <div class="set-block">
            <div class="set-header">
              <p class="set-title">Set 1-1</p>
              <span class="tag subcap">Comprehension & Memory</span>
            </div>
            <div class="audio-grid">
              <audio class="demo-audio" controls preload="none" aria-label="Semantic 1-1 ‚Äî turn 1">
                <source src="static/audio/1-1-turn1_sem.wav" type="audio/wav">
                Your browser does not support the audio element.
              </audio>
              <audio class="demo-audio" controls preload="none" aria-label="Semantic 1-1 ‚Äî turn 2">
                <source src="static/audio/1-1-turn2_sem.wav" type="audio/wav">
              </audio>
            </div>
          </div>

          <!-- Set 2: Reasoning & Execution -->
          <div class="set-block">
            <div class="set-header">
              <p class="set-title">Set 1-2</p>
              <span class="tag subcap">Reasoning & Execution</span>
            </div>
            <div class="audio-grid">
              <audio class="demo-audio" controls preload="none" aria-label="Semantic 1-2 ‚Äî turn 1">
                <source src="static/audio/1-4-turn1_sem.wav" type="audio/wav">
              </audio>
              <audio class="demo-audio" controls preload="none" aria-label="Semantic 1-2 ‚Äî turn 2">
                <source src="static/audio/1-4-turn2_sem.wav" type="audio/wav">
              </audio>
            </div>
          </div>

          <!-- Set 3: Security & Assessment -->
          <div class="set-block">
            <div class="set-header">
              <p class="set-title">Set 1-3</p>
              <span class="tag subcap">Security & Assessment</span>
            </div>
            <div class="audio-grid">
              <audio class="demo-audio" controls preload="none" aria-label="Semantic 1-3 ‚Äî turn 1">
                <source src="static/audio/1-10-turn1_sem.wav" type="audio/wav">
              </audio>
              <audio class="demo-audio" controls preload="none" aria-label="Semantic 1-3 ‚Äî turn 2">
                <source src="static/audio/1-10-turn2_sem.wav" type="audio/wav">
              </audio>
            </div>
          </div>
        </div>
      </div>

      <!-- Paralinguistic -->
      <div class="column is-12-tablet is-4-desktop">
        <div class="box demo-card" data-demo="Paralinguistic">
          <h3 class="title is-5">Paralinguistic</h3>
          <p class="description">
            Tasks emphasize tone, emotion, emphasis, and prosody.
          </p>

          <!-- Set 1: Emotion Recognition -->
          <div class="set-block">
            <div class="set-header">
              <p class="set-title">Set 1-1</p>
              <span class="tag subcap">Emotion Recognition</span>
            </div>
            <div class="audio-grid">
              <audio class="demo-audio" controls preload="none" aria-label="Paralinguistic 1-1 ‚Äî turn 1">
                <source src="static/audio/1-1-turn1_para.wav" type="audio/wav">
              </audio>
              <audio class="demo-audio" controls preload="none" aria-label="Paralinguistic 1-1 ‚Äî turn 2">
                <source src="static/audio/1-1-turn2_para.wav" type="audio/wav">
              </audio>
            </div>
          </div>

          <!-- Set 2: Personalized Expressive Modeling -->
          <div class="set-block">
            <div class="set-header">
              <p class="set-title">Set 1-2</p>
              <span class="tag subcap">Personalized Modeling</span>
            </div>
            <div class="audio-grid">
              <audio class="demo-audio" controls preload="none" aria-label="Paralinguistic 1-2 ‚Äî turn 1">
                <source src="static/audio/1-4-turn1_para.wav" type="audio/wav">
              </audio>
              <audio class="demo-audio" controls preload="none" aria-label="Paralinguistic 1-2 ‚Äî turn 2">
                <source src="static/audio/1-4-turn2_para.wav" type="audio/wav">
              </audio>
            </div>
          </div>

          <!-- Set 3: Feature Generation -->
          <div class="set-block">
            <div class="set-header">
              <p class="set-title">Set 1-3</p>
              <span class="tag subcap">Feature Generation</span>
            </div>
            <div class="audio-grid">
              <audio class="demo-audio" controls preload="none" aria-label="Paralinguistic 1-3 ‚Äî turn 1">
                <source src="static/audio/1-10-turn1_para.wav" type="audio/wav">
              </audio>
              <audio class="demo-audio" controls preload="none" aria-label="Paralinguistic 1-3 ‚Äî turn 2">
                <source src="static/audio/1-10-turn2_para.wav" type="audio/wav">
              </audio>
            </div>
          </div>
        </div>
      </div>

      <!-- Ambient -->
      <div class="column is-12-tablet is-4-desktop">
        <div class="box demo-card" data-demo="Ambient">
          <h3 class="title is-5">Ambient</h3>
          <p class="description">
            Tasks focus on recognizing and leveraging background sounds.
          </p>

          <!-- Set 1: Ambient Sound Understanding -->
          <div class="set-block">
            <div class="set-header">
              <p class="set-title">Set 1-1</p>
              <span class="tag subcap">Sound Understanding</span>
            </div>
            <div class="audio-grid">
              <audio class="demo-audio" controls preload="none" aria-label="Ambient sample1 ‚Äî turn 1">
                <source src="static/audio/1-1-turn1_amb.wav" type="audio/wav">
              </audio>
              <audio class="demo-audio" controls preload="none" aria-label="Ambient sample1 ‚Äî turn 2">
                <source src="static/audio/1-1-turn2_amb.wav" type="audio/wav">
              </audio>
            </div>
          </div>

          <!-- Set 2: Ambient Understanding -->
          <div class="set-block">
            <div class="set-header">
              <p class="set-title">Set 1-2</p>
              <span class="tag subcap">Sound Understanding</span>
            </div>
            <div class="audio-grid">
              <audio class="demo-audio" controls preload="none" aria-label="Ambient sample2 ‚Äî turn 1">
                <source src="static/audio/1-4-turn1_amb.wav" type="audio/wav">
              </audio>
              <audio class="demo-audio" controls preload="none" aria-label="Ambient sample2 ‚Äî turn 2">
                <source src="static/audio/1-4-turn2_amb.wav" type="audio/wav">
              </audio>
            </div>
          </div>

          <!-- Set 3: Multi-party Understanding -->
          <div class="set-block">
            <div class="set-header">
              <p class="set-title">Set 1-3</p>
              <span class="tag subcap">Multi-party Understanding</span>
            </div>
            <div class="audio-grid">
              <audio class="demo-audio" controls preload="none" aria-label="Ambient sample3 ‚Äî turn 1">
                <source src="static/audio/1-10-turn1_amb.wav" type="audio/wav">
              </audio>
              <audio class="demo-audio" controls preload="none" aria-label="Ambient sample3 ‚Äî turn 2">
                <source src="static/audio/1-10-turn2_amb.wav" type="audio/wav">
              </audio>
            </div>
          </div>
        </div>
      </div>

    </div><!-- /columns -->
  </div>
</section>
  

<!-- Results Carousel (figures only, concise captions; English-only) -->
<section class="hero is-small" id="pdf-results">
  <div class="hero-body">
    <div class="container">
      <div class="carousel-container results-carousel-container">
        <div class="carousel-wrapper" id="results-carousel-wrapper">

          <!-- Slide: Overall results -->
          <div class="carousel-item results-carousel-item">
            <div class="card" style="border-radius:16px;">
              <div class="card-content">
                <figure class="image">
                  <img src="static/images/audio_eval.png" alt="Overall evaluation results">
                  <figcaption class="figure-caption">
                    <strong>Overall results (Table 2).</strong> Arena (Elo, relative) and Rubrics (√ó100, absolute)
                    present a consistent landscape across overall and per-dimension scores.
                  </figcaption>
                </figure>
              </div>
            </div>
          </div>

          <!-- Slide: Win rates across evaluators -->
          <div class="carousel-item results-carousel-item">
            <div class="card" style="border-radius:16px;">
              <div class="card-content">
                <figure class="image">
                  <img src="static/images/win_rates.png" alt="Win rates across evaluators">
                  <figcaption class="figure-caption">
                    <strong>Win-rate profiles.</strong> Cross-evaluator win rates show strong systems,
                    yet many model pairs remain statistically tied rather than yielding a single dominant system.
                  </figcaption>
                </figure>
              </div>
            </div>
          </div>

          <!-- Slide: Turn-level trends & duration correlation -->
          <div class="carousel-item results-carousel-item">
            <div class="card" style="border-radius:16px;">
              <div class="card-content">
                <figure class="image">
                  <img src="static/images/turn_level_trends.png" alt="Turn-level trends and duration correlation">
                  <figcaption class="figure-caption">
                    <strong>Turn-level trends &amp; duration correlation.</strong> Quality often dips in early turns and then recovers
                    as responses become longer; duration correlates with higher scores, but gains plateau beyond a minimal length.
                  </figcaption>
                </figure>
              </div>
            </div>
          </div>

          <!-- Slide: Bias analysis -->
          <div class="carousel-item results-carousel-item">
            <div class="card" style="border-radius:16px;">
              <div class="card-content">
                <figure class="image">
                  <img src="static/images/bias_analysis.png" alt="Bias analysis of evaluators">
                  <figcaption class="figure-caption">
                    <strong>LLM-as-judge bias.</strong> Compared to humans (near-neutral positional preference),
                    LLM judges exhibit measurable <em>position</em> and stronger <em>length</em> biases in Arena scoring.
                  </figcaption>
                </figure>
              </div>
            </div>
          </div>

          <!-- Slide: Arena‚ÄìRubrics consistency & pitfalls -->
          <div class="carousel-item results-carousel-item">
            <div class="card" style="border-radius:16px;">
              <div class="card-content">
                <figure class="image">
                  <img src="static/images/arena_rubrics_consistency.png" alt="Consistency and pitfalls">
                  <figcaption class="figure-caption">
                    <strong>Consistency &amp; pitfalls.</strong> The two protocols are broadly consistent with good internal reliability;
                    however, when performance gaps are small, conclusions remain unstable even with more comparisons.
                  </figcaption>
                </figure>
              </div>
            </div>
          </div>

        </div>

        <!-- Navigation -->
        <button class="carousel-nav carousel-nav-left" id="results-prev" aria-label="Previous result">
          <i class="fas fa-chevron-left" aria-hidden="true"></i>
        </button>
        <button class="carousel-nav carousel-nav-right" id="results-next" aria-label="Next result">
          <i class="fas fa-chevron-right" aria-hidden="true"></i>
        </button>
      </div>

      <!-- Pagination -->
      <div class="carousel-pagination" id="results-pagination" aria-label="Results pagination">
        <span class="carousel-dot active" data-slide="0"></span>
        <span class="carousel-dot" data-slide="1"></span>
        <span class="carousel-dot" data-slide="2"></span>
        <span class="carousel-dot" data-slide="3"></span>
        <span class="carousel-dot" data-slide="4"></span>
      </div>
    </div>
  </div>
</section>

<!-- Results: Model Performance (English-only) -->
<section class="section" id="results-analysis">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Experiment Results ‚Äî Model Performance</h2>
    <div class="content has-text-justified">
      <ul class="key-findings">
        <li><strong>Dimension gap:</strong> Models perform best on the <em>Semantic</em> dimension and lag on <em>Paralinguistic</em> and <em>Ambient</em> tasks.</li>
        <li><strong>Dialogue dynamics:</strong> Early-turn quality often dips and later recovers with longer outputs; duration correlates with higher scores but shows diminishing returns.</li>
        <li><strong>Design matters:</strong> Modality-aware, task-specific designs generally outperform brute parameter scaling for multi-turn S2S dialogue.</li>
      </ul>
    </div>
  </div>
</section>

<!-- Meta-Evaluation: Methods & Reliability (English-only) -->
<section class="section" id="meta-eval">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Meta-Evaluation ‚Äî Methods &amp; Reliability</h2>
    <div class="content has-text-justified">
      <ul class="key-findings">
        <li><strong>Arena √ó Rubrics:</strong> Broadly consistent and complementary ‚Äî relative ordering vs. absolute diagnostics.</li>
        <li><strong>Small margins:</strong> When gaps are small, outcomes remain unstable even with more pairwise comparisons; robust conclusions appear with large gaps.</li>
        <li><strong>LLM-as-judge:</strong> Agreement with humans improves when differences are clear or criteria are explicit, but LLMs show position and length biases; for nonverbal acoustic cues, reliability improves with textual annotations.</li>
        <li><strong>Reliability:</strong> Good internal consistency across protocols; rubric-based assessments show stable correlations under ablations/bootstraps.</li>
      </ul>
    </div>
  </div>
</section>


  

  <!-- BibTeX -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{mtalk-bench-2024,
  title={MTalk-Bench: Evaluating Speech-to-Speech Models in Multi-Turn Dialogues via Arena-style and Rubrics Protocols},
  author={First Author and Second Author and Third Author},
  journal={Conference Name},
  year={2024}
}</code></pre>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <script>
    // Custom Carousel Implementation
    class CustomCarousel {
      constructor(wrapperId, paginationId, prevBtnId, nextBtnId) {
        this.wrapper = document.getElementById(wrapperId);
        this.pagination = document.getElementById(paginationId);
        this.prevBtn = document.getElementById(prevBtnId);
        this.nextBtn = document.getElementById(nextBtnId);
        this.items = this.wrapper.querySelectorAll('.carousel-item');
        this.currentIndex = 0;
        this.autoplayInterval = null;
        
        this.init();
      }
      
      init() {
        this.updateCarousel();
        this.bindEvents();
        this.startAutoplay();
      }
      
      bindEvents() {
        this.prevBtn.addEventListener('click', () => this.prev());
        this.nextBtn.addEventListener('click', () => this.next());
        
        this.pagination.querySelectorAll('.carousel-dot').forEach((dot, index) => {
          dot.addEventListener('click', () => this.goToSlide(index));
        });
        
        // Pause autoplay on hover
        this.wrapper.addEventListener('mouseenter', () => this.stopAutoplay());
        this.wrapper.addEventListener('mouseleave', () => this.startAutoplay());
      }
      
      updateCarousel() {
        const translateX = -this.currentIndex * 100;
        this.wrapper.style.transform = `translateX(${translateX}%)`;
      
        // Update pagination
        this.pagination.querySelectorAll('.carousel-dot').forEach((dot, index) => {
          dot.classList.toggle('active', index === this.currentIndex);
        });
      }
      
      next() {
        this.currentIndex = (this.currentIndex + 1) % this.items.length;
        this.updateCarousel();
      }
      
      prev() {
        this.currentIndex = (this.currentIndex - 1 + this.items.length) % this.items.length;
        this.updateCarousel();
      }
      
      goToSlide(index) {
        this.currentIndex = index;
        this.updateCarousel();
      }
      
      startAutoplay() {
        this.stopAutoplay();
        this.autoplayInterval = setInterval(() => this.next(), 5000);
      }
      
      stopAutoplay() {
        if (this.autoplayInterval) {
          clearInterval(this.autoplayInterval);
          this.autoplayInterval = null;
        }
      }
    }

    // Initialize carousels when DOM is loaded
    document.addEventListener('DOMContentLoaded', () => {
      // Initialize framework figures carousel
      new CustomCarousel(
        'fig-carousel-wrapper',
        'fig-pagination', 
        'fig-prev',
        'fig-next'
      );
      
      // Initialize results carousel (no autoplay)
      const resultsCarousel = new CustomCarousel(
        'results-carousel-wrapper',
        'results-pagination',
        'results-prev', 
        'results-next'
      );
      resultsCarousel.stopAutoplay(); // Disable autoplay for results
    });
  </script>

</body>
</html>

<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="MTalk-Bench: Evaluating Speech-to-Speech Models in Multi-Turn Dialogues">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>MTalk-Bench: Evaluating Speech-to-Speech Models in Multi-Turn Dialogues via Arena-style and Rubrics Protocols</title>
  
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.4/css/bulma.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.4/css/academicons.min.css">

  <style>
    body {
      font-family: 'Noto Sans', sans-serif;
    }

    .publication-title {
      font-family: 'Google Sans', sans-serif;
    }

    .publication-authors {
      font-family: 'Google Sans', sans-serif;
    }

    .publication-authors a {
      color: hsl(204, 86%, 53%) !important;
    }

    .publication-authors a:hover {
      text-decoration: underline;
    }

    .author-block {
      display: inline-block;
    }

    .eql-cntrb { 
      font-size: smaller;
    }

    /* Custom Carousel Styles */
    .carousel-container {
      position: relative;
      overflow: hidden;
      width: 100%;
      height: 500px; /* å‡å°‘é«˜åº¦ */
    }

    .carousel-wrapper {
      display: flex;
      transition: transform 0.5s ease-in-out;
      height: 100%;
    }

    .carousel-item {
      flex: 0 0 100%;          /* ç²¾ç¡®å æ»¡ä¸€å±ï¼Œç­‰ä»·äº width: 100% ä¸”ä¸æ”¶ç¼© */
      box-sizing: border-box;  /* æŠŠ padding è®¡ç®—è¿› 100% å®½åº¦ï¼Œé¿å…æº¢å‡º */
      display: flex;
      align-items: center;
      justify-content: center;
      padding: 1rem;
    }

    .carousel-item figure {
      width: 100%;
      max-width: 900px; /* å¢åŠ æœ€å¤§å®½åº¦ */
      margin: 0 auto;
    }

    .carousel-item img {
      width: 100%;
      height: auto;
      border-radius: 12px;
      box-shadow: 0 8px 32px rgba(0,0,0,0.1);
    }

    /* Navigation buttons */
    .carousel-nav {
      position: absolute;
      top: 50%;
      transform: translateY(-50%);
      background: rgba(0,0,0,0.7);
      color: white;
      border: none;
      width: 50px;
      height: 50px;
      border-radius: 50%;
      cursor: pointer;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 18px;
      z-index: 10;
      transition: background-color 0.3s ease;
    }

    .carousel-nav:hover {
      background: rgba(0,0,0,0.9);
    }

    .carousel-nav-left {
      left: 20px;
    }

    .carousel-nav-right {
      right: 20px;
    }

    /* Pagination dots */
    .carousel-pagination {
      display: flex;
      justify-content: center;
      gap: 10px;
      margin-top: 1rem;
    }

    .carousel-dot {
      width: 12px;
      height: 12px;
      border-radius: 50%;
      background: #ccc;
      cursor: pointer;
      transition: background-color 0.3s ease;
    }

    .carousel-dot.active {
      background: #3273dc;
    }

    /* Demo cards styling */
    .demo-card {
      background: white;
      border-radius: 16px;
      padding: 2rem;
      box-shadow: 0 4px 20px rgba(0,0,0,0.1);
      height: 100%;
    }

    .demo-audio {
      width: 100%;
      margin-bottom: 0.5rem;
    }

    .set-block {
      border-left: 3px solid #3273dc;
      padding-left: 1rem;
      margin: 1rem 0;
    }

    .demo-card .subcap {
      border-radius: 9999px;
      padding: 0.25rem 0.6rem;
      font-weight: 600;
      border: none;
    }
    
    /* åˆ†åœºæ™¯é…è‰²ï¼šå„è‡ªå”¯ä¸€é¢œè‰² */
    .demo-card[data-demo="Semantic"] .subcap {
      background-color: #2b8a3e; /* ç»¿è‰² */
      color: #fff;
    }
    .demo-card[data-demo="Paralinguistic"] .subcap {
      background-color: #6f42c1; /* ç´«è‰² */
      color: #fff;
    }
    .demo-card[data-demo="Ambient"] .subcap {
      background-color: #1e88e5; /* è“è‰² */
      color: #fff;
    }
    .key-findings li {
      margin-bottom: 1rem;
      padding: 0.5rem 0;
    }

    /* Results carousel specific styling - è°ƒæ•´å¸ƒå±€ä½¿captionåœ¨å›¾ç‰‡ä¸‹æ–¹ */
    .results-carousel-container {
      height: 600px; /* å‡å°‘é«˜åº¦ */
    }

    .results-carousel-item .card {
      height: 100%;
      display: flex;
      flex-direction: column;
    }

    .results-carousel-item .card-content {
      flex: 1;
      display: flex;
      flex-direction: column;
      padding: 0.5rem; /* å‡å°‘å†…è¾¹è· */
    }

    .results-carousel-item figure {
      flex: 1;
      display: flex;
      flex-direction: column; /* æ”¹ä¸ºçºµå‘å¸ƒå±€ */
      justify-content: center;
      align-items: center;
      margin: 0; /* ç§»é™¤é»˜è®¤è¾¹è· */
    }

    .results-carousel-item figure img {
      width: 100%;
      height: auto;
      max-height: 450px; /* å‡å°‘å›¾ç‰‡æœ€å¤§é«˜åº¦ */
      object-fit: contain;
    }

    .figure-caption,
    .image-caption {
      margin-top: 0.75rem; /* å‡å°‘ä¸Šè¾¹è· */
      margin-bottom: 0; /* ç§»é™¤ä¸‹è¾¹è· */
      font-size: 0.95rem;
      line-height: 1.4;
      color: rgba(0,0,0,0.7);
      text-align: center;
      width: 100%;
    }

    /* å‡å°‘sectionä¹‹é—´çš„é—´è· */
    .section {
      padding: 2rem 1.5rem; /* å‡å°‘sectionçš„padding */
    }

    .hero.is-small .hero-body {
      padding: 1.5rem 1.5rem; /* å‡å°‘heroçš„padding */
    }

    /* Compact spacing for the two findings sections */
    #results-analysis .content,
    #meta-eval .content {
      line-height: 1.5;              /* æ”¶ç´§æ®µå†…è¡Œè· */
    }
    
    #results-analysis .key-findings,
    #meta-eval .key-findings {
      margin-top: 0.25rem;           /* æ”¶ç´§åˆ—è¡¨ä¸Šä¸‹ç©ºç™½ */
      margin-bottom: 0.75rem;
    }
    
    #results-analysis .key-findings li,
    #meta-eval .key-findings li {
      margin-bottom: 0.35rem;        /* æ”¶ç´§æ¡ç›®é—´è·ï¼ˆåŸæ¥æ˜¯ 1remï¼‰ */
      padding: 0.15rem 0;            /* æ”¶ç´§æ¡ç›®å†…è¾¹è·ï¼ˆåŸæ¥æ˜¯ 0.5rem 0ï¼‰ */
      line-height: 1.45;             /* å­å¼¹æ¡ç›®æ–‡æœ¬è¡Œè·æ›´ç´§ä¸€ç‚¹ */
    }
  </style>
</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">MTalk-Bench: Evaluating Speech-to-Speech Models in Multi-Turn Dialogues via Arena-style and Rubrics Protocols</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="mailto:yuhaodu1@link.cuhk.edu.cn" target="_blank">Yuhao Du</a><sup>*</sup>,
              </span>
              <span class="author-block">
                <a href="mailto:qianweihuang@link.cuhk.edu.cn" target="_blank">Qianwei Huang</a><sup>*</sup>,
              </span>
              <span class="author-block">
                <a href="#" target="_blank">Guo Zhu</a>,
              </span>
              <span class="author-block">
                <a href="#" target="_blank">Zhanchen Dai</a>,
              </span>
              <span class="author-block">
                <a href="#" target="_blank">Sunian Chen</a>,
              </span>
              <span class="author-block">
                <a href="#" target="_blank">Qiming Zhu</a>,
              </span>
              <span class="author-block">
                <a href="#" target="_blank">Yuhao Zhang</a>,
              </span>
              <span class="author-block">
                <a href="#" target="_blank">Li Zhou</a>,
              </span>
              <span class="author-block">
                and <a href="mailto:wangbenyou@link.cuhk.edu.cn" target="_blank">Benyou Wang</a><sup>â€ </sup>
              </span>
            </div>

            <div class="is-size-6 publication-authors">
              <span class="author-block">
                School of Data Science, The Chinese University of Hong Kong, Shenzhen
              </span><br>
              <a href="https://freedomintelligence.github.io/MTalk-Bench/" target="_blank">
                https://freedomintelligence.github.io/MTalk-Bench/
              </a>
            </div>
  
            <div class="is-size-6 eql-cntrb" style="margin-top: 0.75em;">
              <small>
                <sup>*</sup> Equal contribution. <sup>â€ </sup> Corresponding author.
              </small>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="#" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="fas fa-file-pdf"></i></span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://huggingface.co/datasets/FreedomIntelligence/MTalk-Bench" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span>ğŸ¤— Dataset</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://github.com/FreedomIntelligence/MTalk-Bench" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="fab fa-github"></i></span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              The rapid advancement of speech-to-speech (S2S) large language models (LLMs) has significantly improved real-time spoken interaction.  However, current evaluation frameworks remain inadequate for assessing performance in complex, multi-turn dialogues. 
              To address this, we introduce <strong>MTalk-Bench</strong>, a multi-turn S2S benchmark covering three core dimensions: 
              <em>Semantic Information</em>, <em>Paralinguistic Information</em>, and <em>Ambient Sound</em>. 
              Each dimension includes nine realistic scenarios, along with targeted tasks to assess specific capabilities such as reasoning. 
              Our dual-method evaluation framework combines <em>Arena-style</em> evaluation (pairwise comparison) and <em>Rubrics-based</em> 
              evaluation (absolute scoring) for relative and absolute assessment. The benchmark includes both model and human outputs, evaluated by 
              human evaluators and LLMs. 
              Experimental results reveal two sets of findings. <strong>Overall performance of S2S LLMs:</strong> 
              (1) models excel at semantic information processing yet underperform on paralinguistic information and ambient sounds perception; 
              (2) Models typically regain coherence by increasing response length, sacrificing efficiency in multi-turn dialogues; 
              (3) modality-aware, task-specific designs outperform brute scaling. 
              <strong>Evaluation framework and reliability:</strong> 
              (1) Arena and Rubrics yield consistent, complementary rankings, but reliable distinctions emerge only when performance gaps are large; 
              (2) LLM-as-a-judge aligns with humans when gaps are clear or criteria explicit, but exhibits position and length biases and is reliable 
              on nonverbal evaluation only with text annotations. 
              These results highlight current limitations in S2S evaluation and the need for more robust, speech-aware assessment frameworks.
            </p>

          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Framework & Evaluation (Condensed, English-only) -->
<section class="section" id="framework-eval">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Framework &amp; Evaluation</h2>

    <!-- Figures: concise academic captions -->
    <section class="hero is-small" id="figures">
      <div class="hero-body">
        <div class="container">
          <div class="carousel-container">
            <div class="carousel-wrapper" id="fig-carousel-wrapper">
              <!-- Slide 1 -->
              <div class="carousel-item">
                <figure class="image">
                  <img src="static/images/main_structure_comics_new.png" alt="Framework overview" loading="lazy">
                  <figcaption class="figure-caption">
                    <strong>Figure 1. MTalk-Bench overview.</strong> Three speech-aware dimensions
                    (Semantic, Paralinguistic, Ambient) organized into a hierarchical capability taxonomy,
                    evaluated via a <em>dual-method</em> design: Arena-style and rubric-based evaluation,
                    executed by both human raters and LLM-as-a-judge.
                  </figcaption>
                </figure>
              </div>

              <!-- Slide 2 -->
              <div class="carousel-item">
                <figure class="image">
                  <img src="static/images/Data_construction_comics_new.png" alt="Data pipeline" loading="lazy">
                  <figcaption class="figure-caption">
                    <strong>Figure 2. Data construction pipeline.</strong> Scenario-capability mapping â†’ multi-turn script authoring â†’
                    human speech recording â†’ Seed-VC timbre conversion (for child/elder voices) â†’ ambient-sound integration â†’ quality checking â†’ inputs to Arena &amp; Rubrics evaluations.
                  </figcaption>
                </figure>
              </div>
            </div>

            <!-- Navigation -->
            <button class="carousel-nav carousel-nav-left" id="fig-prev" aria-label="Previous figure">
              <i class="fas fa-chevron-left" aria-hidden="true"></i>
            </button>
            <button class="carousel-nav carousel-nav-right" id="fig-next" aria-label="Next figure">
              <i class="fas fa-chevron-right" aria-hidden="true"></i>
            </button>
          </div>

          <!-- Pagination -->
          <div class="carousel-pagination" id="fig-pagination" aria-label="Figures pagination">
            <span class="carousel-dot active" data-slide="0"></span>
            <span class="carousel-dot" data-slide="1"></span>
          </div>
        </div>
      </div>
    </section>

    <!-- Text: concise and academic (no duplication with figure captions) -->
    <div class="columns is-variable is-6 is-multiline">
      <div class="column is-12">
        <div class="content has-text-justified">
          <p>
            MTalk-Bench spans <em>Semantic</em>, <em>Paralinguistic</em>, and <em>Ambient</em> dimensions, with a two-level capability taxonomy
            (foundational capabilities â†’ fine-grained capabilities). Nine real-world scenarios are linked via a scenario-capability mapping to ensure ecological validity
            while keeping each dialogue diagnostic by design.
          </p>

          <p>
            We use complementary protocols: <strong>Arena-style</strong> evaluation (blind pairwise preferences aggregated as Elo for relative ordering)
            and <strong>Rubric-based</strong> evaluation (hierarchical, criteria-based scoring for absolute diagnostics). Both human raters and LLM-as-a-judge
            are employed to do the evaluation.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


  
<section class="section" id="demos">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Audio Demos</h2>

    <div class="columns is-multiline is-variable is-4">

      <!-- Semantic -->
      <div class="column is-12-tablet is-4-desktop">
        <div class="box demo-card" data-demo="Semantic">
          <h3 class="title is-5">Semantic</h3>

          <!-- Set 1: Comprehension & Memory -->
          <div class="set-block">
            <div class="set-header">
              <p class="set-title">sample 1</p>
              <span class="tag subcap">Comprehension & Memory</span>
            </div>
            <div class="audio-grid">
              <audio class="demo-audio" controls preload="none" aria-label="Semantic 1-1 â€” turn 1">
                <source src="static/audio/1-1-turn1_sem.wav" type="audio/wav">
                Your browser does not support the audio element.
              </audio>
              <audio class="demo-audio" controls preload="none" aria-label="Semantic 1-1 â€” turn 2">
                <source src="static/audio/1-1-turn2_sem.wav" type="audio/wav">
              </audio>
            </div>
          </div>

          <!-- Set 2: Reasoning & Execution -->
          <div class="set-block">
            <div class="set-header">
              <p class="set-title">sample 2</p>
              <span class="tag subcap">Reasoning & Execution</span>
            </div>
            <div class="audio-grid">
              <audio class="demo-audio" controls preload="none" aria-label="Semantic 1-2 â€” turn 1">
                <source src="static/audio/1-4-turn1_sem.wav" type="audio/wav">
              </audio>
              <audio class="demo-audio" controls preload="none" aria-label="Semantic 1-2 â€” turn 2">
                <source src="static/audio/1-4-turn2_sem.wav" type="audio/wav">
              </audio>
            </div>
          </div>

          <!-- Set 3: Security & Assessment -->
          <div class="set-block">
            <div class="set-header">
              <p class="set-title">sample 3</p>
              <span class="tag subcap">Security & Assessment</span>
            </div>
            <div class="audio-grid">
              <audio class="demo-audio" controls preload="none" aria-label="Semantic 1-3 â€” turn 1">
                <source src="static/audio/1-10-turn1_sem.wav" type="audio/wav">
              </audio>
              <audio class="demo-audio" controls preload="none" aria-label="Semantic 1-3 â€” turn 2">
                <source src="static/audio/1-10-turn2_sem.wav" type="audio/wav">
              </audio>
            </div>
          </div>
        </div>
      </div>

      <!-- Paralinguistic -->
      <div class="column is-12-tablet is-4-desktop">
        <div class="box demo-card" data-demo="Paralinguistic">
          <h3 class="title is-5">Paralinguistic</h3>

          <!-- Set 1: Emotion Recognition -->
          <div class="set-block">
            <div class="set-header">
              <p class="set-title">Set 1-1</p>
              <span class="tag subcap">Emotion Recognition</span>
            </div>
            <div class="audio-grid">
              <audio class="demo-audio" controls preload="none" aria-label="Paralinguistic 1-1 â€” turn 1">
                <source src="static/audio/1-1-turn1_para.wav" type="audio/wav">
              </audio>
              <audio class="demo-audio" controls preload="none" aria-label="Paralinguistic 1-1 â€” turn 2">
                <source src="static/audio/1-1-turn2_para.wav" type="audio/wav">
              </audio>
            </div>
          </div>

          <!-- Set 2: Personalized Expressive Modeling -->
          <div class="set-block">
            <div class="set-header">
              <p class="set-title">sample 2</p>
              <span class="tag subcap">Personalized Modeling</span>
            </div>
            <div class="audio-grid">
              <audio class="demo-audio" controls preload="none" aria-label="Paralinguistic 1-2 â€” turn 1">
                <source src="static/audio/1-4-turn1_para.wav" type="audio/wav">
              </audio>
              <audio class="demo-audio" controls preload="none" aria-label="Paralinguistic 1-2 â€” turn 2">
                <source src="static/audio/1-4-turn2_para.wav" type="audio/wav">
              </audio>
            </div>
          </div>

          <!-- Set 3: Feature Generation -->
          <div class="set-block">
            <div class="set-header">
              <p class="set-title">sample 3</p>
              <span class="tag subcap">Paralinguistic Feature Generation</span>
            </div>
            <div class="audio-grid">
              <audio class="demo-audio" controls preload="none" aria-label="Paralinguistic 1-3 â€” turn 1">
                <source src="static/audio/1-10-turn1_para.wav" type="audio/wav">
              </audio>
              <audio class="demo-audio" controls preload="none" aria-label="Paralinguistic 1-3 â€” turn 2">
                <source src="static/audio/1-10-turn2_para.wav" type="audio/wav">
              </audio>
            </div>
          </div>
        </div>
      </div>

      <!-- Ambient -->
      <div class="column is-12-tablet is-4-desktop">
        <div class="box demo-card" data-demo="Ambient">
          <h3 class="title is-5">Ambient</h3>


          <!-- Set 1: Ambient Sound Understanding -->
          <div class="set-block">
            <div class="set-header">
              <p class="set-title">Set 1-1</p>
              <span class="tag subcap">Ambient Sound Understanding</span>
            </div>
            <div class="audio-grid">
              <audio class="demo-audio" controls preload="none" aria-label="Ambient sample1 â€” turn 1">
                <source src="static/audio/1-1-turn1_amb.wav" type="audio/wav">
              </audio>
              <audio class="demo-audio" controls preload="none" aria-label="Ambient sample1 â€” turn 2">
                <source src="static/audio/1-1-turn2_amb.wav" type="audio/wav">
              </audio>
            </div>
          </div>

          <!-- Set 2: Ambient Understanding -->
          <div class="set-block">
            <div class="set-header">
              <p class="set-title">sample 2</p>
              <span class="tag subcap">Ambient Sound Understanding</span>
            </div>
            <div class="audio-grid">
              <audio class="demo-audio" controls preload="none" aria-label="Ambient sample2 â€” turn 1">
                <source src="static/audio/1-4-turn1_amb.wav" type="audio/wav">
              </audio>
              <audio class="demo-audio" controls preload="none" aria-label="Ambient sample2 â€” turn 2">
                <source src="static/audio/1-4-turn2_amb.wav" type="audio/wav">
              </audio>
            </div>
          </div>

          <!-- Set 3: Multi-party Understanding -->
          <div class="set-block">
            <div class="set-header">
              <p class="set-title">sample 3</p>
              <span class="tag subcap">Multi-party Understanding</span>
            </div>
            <div class="audio-grid">
              <audio class="demo-audio" controls preload="none" aria-label="Ambient sample3 â€” turn 1">
                <source src="static/audio/1-10-turn1_amb.wav" type="audio/wav">
              </audio>
              <audio class="demo-audio" controls preload="none" aria-label="Ambient sample3 â€” turn 2">
                <source src="static/audio/1-10-turn2_amb.wav" type="audio/wav">
              </audio>
            </div>
          </div>
        </div>
      </div>

    </div><!-- /columns -->
  </div>
</section>
  

<section class="hero is-small" id="pdf-results">
  <div class="hero-body">
    <h2 class="title is-3 has-text-centered">Results Analysis</h2>
    <div class="container">
      <div class="carousel-container results-carousel-container">
        
        <div class="carousel-wrapper" id="results-carousel-wrapper">

          <!-- Slide: Overall results -->
          <div class="carousel-item results-carousel-item">
            <div class="card" style="border-radius:16px;">
              <div class="card-content">
                <figure class="image">
                  <img src="static/images/audio_eval.png" alt="Overall evaluation results">
                  <figcaption class="figure-caption">
                    <strong>Figure 3. Evaluation Results (Table 2)</strong> â€” Arena: Elo ratings per dimension and overall; Rubrics: absolute scores (Ã—100). Models sorted by human overall score; â†‘ = better.
                  </figcaption>
                </figure>
              </div>
            </div>
          </div>

          <!-- Slide: Win rates across evaluators -->
          <div class="carousel-item results-carousel-item">
            <div class="card" style="border-radius:16px;">
              <div class="card-content">
                <figure class="image">
                  <img src="static/images/win_rates.png" alt="Win rates across evaluators">
                  <figcaption class="figure-caption">
                    <strong>Figure 4. Win rate of models</strong> â€” Illustrate win rates of different models across different evaluators in arena-style evaluation, revealing numerous statistically tied outcomes rather than a single dominant system.
                  </figcaption>
                </figure>
              </div>
            </div>
          </div>

          <!-- Slide: Turn-level trends & duration correlation -->
          <div class="carousel-item results-carousel-item">
            <div class="card" style="border-radius:16px;">
              <div class="card-content">
                <figure class="image">
                  <img src="static/images/turn_level_trends.png" alt="Turn-level trends and duration correlation">
                  <figcaption class="figure-caption">
                    <strong>Figure 5. Turn-level trends</strong> â€” Quality often dips in early turns and recovers as models produce longer outputs; audio duration correlates with higher Arena/Rubrics scores, but after a minimal length the gains plateau, indicating that verbosity â‰  quality.
                  </figcaption>
                </figure>
              </div>
            </div>
          </div>

          <!-- Slide: Bias analysis -->
          <div class="carousel-item results-carousel-item">
            <div class="card" style="border-radius:16px;">
              <div class="card-content">
                <figure class="image">
                  <img src="static/images/bias_analysis.png" alt="Bias analysis of evaluators">
                  <figcaption class="figure-caption">
                    <strong>Figure 6. Bias analysis of evaluators</strong> â€” Compared to humans (near-neutral positional preference), LLM judges exhibit measurable <em>position</em> and stronger <em>length</em> biases when scoring Arena pairs (e.g., length bias significantly positive) these structural biases should be accounted for in automated judging.
                  </figcaption>
                </figure>
              </div>
            </div>
          </div>

          <!-- Slide: Arenaâ€“Rubrics consistency & pitfalls -->
          <div class="carousel-item results-carousel-item">
            <div class="card" style="border-radius:16px;">
              <div class="card-content">
                <figure class="image">
                  <img src="static/images/arena_rubrics_consistency.png" alt="Consistency and pitfalls">
                  <figcaption class="figure-caption">
                    <strong>Figure 7. Consistency of Arena and Rubrics</strong> â€” Internal logical consistency of each evaluator across the Arena-style and Rubric-based formats. The results show that all evaluators are validated for their judgmentsâ€™ reliability regardless of the evaluation format.
                  </figcaption>
                </figure>
              </div>
            </div>
          </div>

        </div>

        <!-- Navigation -->
        <button class="carousel-nav carousel-nav-left" id="results-prev" aria-label="Previous result">
          <i class="fas fa-chevron-left" aria-hidden="true"></i>
        </button>
        <button class="carousel-nav carousel-nav-right" id="results-next" aria-label="Next result">
          <i class="fas fa-chevron-right" aria-hidden="true"></i>
        </button>
      </div>

      <!-- Pagination -->
      <div class="carousel-pagination" id="results-pagination" aria-label="Results pagination">
        <span class="carousel-dot active" data-slide="0"></span>
        <span class="carousel-dot" data-slide="1"></span>
        <span class="carousel-dot" data-slide="2"></span>
        <span class="carousel-dot" data-slide="3"></span>
        <span class="carousel-dot" data-slide="4"></span>
      </div>
    </div>
  </div>
</section>
  

<!-- Results: Model Performance -->
<section class="section" id="results-analysis">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Experiment Results â€” Model Performance</h2>
    <div class="content has-text-justified">
      <ul class="key-findings">
        <li><strong>Dimension gap:</strong> Top models have not yet reached high proficiency. They are overall strong in <em>semantics</em> but limited in <em>some specific semantic capability</em> like safety reasoning and <em>auditory cues (paralinguistic and ambient sound perception)</em>.</li>
        <li><strong>Dialogue dynamics:</strong> Models recover from an early-turn quality dip by producing longer responses, trading efficiency for coherence. After a minimal length for clarity, more tokens often mean more fluff, not better answers.</li>
        <li><strong>Design matters:</strong> When paired with large capacity, task specific designs deliver bigger gains than scale alone.</li>
      </ul>
    </div>
  </div>
</section>

<!-- Meta-Evaluation: Methods & Reliability -->
<section class="section" id="meta-eval">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Meta-Evaluation â€” Methods &amp; Reliability</h2>
    <div class="content has-text-justified">
      <ul class="key-findings">
        <li><strong>Arena Ã— Rubrics:</strong> Broadly consistent and complementary â€” relative ordering vs. absolute diagnostics.</li>
        <li><strong>Small margins:</strong> When gaps are small, outcomes remain unstable even with more pairwise comparisons; robust conclusions appear with large gaps.</li>
        <li><strong>LLM-as-judge:</strong> Agreement with humans improves when differences are clear or criteria are explicit, but LLMs show position and length biases; for nonverbal acoustic cues, reliability improves with textual annotations.</li>
        <li><strong>Reliability:</strong> Good internal consistency across protocols; rubric-based assessments show stable correlations under ablations/bootstraps.</li>
      </ul>
    </div>
  </div>
</section>


  

  <!-- BibTeX -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{mtalk-bench-2024,
  title={MTalk-Bench: Evaluating Speech-to-Speech Models in Multi-Turn Dialogues via Arena-style and Rubrics Protocols},
  author={Yuhao Du, Qianwei Huang, Guo Zhu, Zhanchen Dai, Sunian Chen, Qiming Zhu, Yuhao Zhang, Li Zhou, and Benyou Wang},
  journal={Conference Name},
  year={2025},
  url={https://freedomintelligence.github.io/MTalk-Bench/}
}</code></pre>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <script>
    // Custom Carousel Implementation
    class CustomCarousel {
      constructor(wrapperId, paginationId, prevBtnId, nextBtnId) {
        this.wrapper = document.getElementById(wrapperId);
        this.pagination = document.getElementById(paginationId);
        this.prevBtn = document.getElementById(prevBtnId);
        this.nextBtn = document.getElementById(nextBtnId);
        this.items = this.wrapper.querySelectorAll('.carousel-item');
        this.currentIndex = 0;
        this.autoplayInterval = null;
        
        this.init();
      }
      
      init() {
        this.updateCarousel();
        this.bindEvents();
        this.startAutoplay();
      }
      
      bindEvents() {
        this.prevBtn.addEventListener('click', () => this.prev());
        this.nextBtn.addEventListener('click', () => this.next());
        
        this.pagination.querySelectorAll('.carousel-dot').forEach((dot, index) => {
          dot.addEventListener('click', () => this.goToSlide(index));
        });
        
        // Pause autoplay on hover
        this.wrapper.addEventListener('mouseenter', () => this.stopAutoplay());
        this.wrapper.addEventListener('mouseleave', () => this.startAutoplay());
      }
      
      updateCarousel() {
        const translateX = -this.currentIndex * 100;
        this.wrapper.style.transform = `translateX(${translateX}%)`;
      
        // Update pagination
        this.pagination.querySelectorAll('.carousel-dot').forEach((dot, index) => {
          dot.classList.toggle('active', index === this.currentIndex);
        });
      }
      
      next() {
        this.currentIndex = (this.currentIndex + 1) % this.items.length;
        this.updateCarousel();
      }
      
      prev() {
        this.currentIndex = (this.currentIndex - 1 + this.items.length) % this.items.length;
        this.updateCarousel();
      }
      
      goToSlide(index) {
        this.currentIndex = index;
        this.updateCarousel();
      }
      
      startAutoplay() {
        this.stopAutoplay();
        this.autoplayInterval = setInterval(() => this.next(), 5000);
      }
      
      stopAutoplay() {
        if (this.autoplayInterval) {
          clearInterval(this.autoplayInterval);
          this.autoplayInterval = null;
        }
      }
    }

    // Initialize carousels when DOM is loaded
    document.addEventListener('DOMContentLoaded', () => {
      // Initialize framework figures carousel
      new CustomCarousel(
        'fig-carousel-wrapper',
        'fig-pagination', 
        'fig-prev',
        'fig-next'
      );
      
      // Initialize results carousel (no autoplay)
      const resultsCarousel = new CustomCarousel(
        'results-carousel-wrapper',
        'results-pagination',
        'results-prev', 
        'results-next'
      );
      resultsCarousel.stopAutoplay(); // Disable autoplay for results
    });
  </script>

</body>
</html>
